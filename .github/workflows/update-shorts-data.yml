name: Update Shorts Data

on:
  schedule:
    # ë§¤ì¼ í•œêµ­ ì‹œê°„ ì˜¤ì „ 9ì‹œ (UTC 0ì‹œ)ì— ì‹¤í–‰
    - cron: '0 0 * * *'
  workflow_dispatch:  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          
      - name: Run crawler
        run: |
          cd backend
          python3 -c "
from youtube_shorts_crawler import YouTubeShortsCrawler
print('ğŸš€ í¬ë¡¤ë§ ì‹œì‘...')
crawler = YouTubeShortsCrawler()
videos = crawler.crawl_shorts_trending(200)
crawler.save_to_cache(videos)
print(f'âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(videos)}ê°œ')
          "
          
      - name: Copy data to frontend
        run: |
          cp data/youtube_shorts_cache.json frontend/src/data/realData.json
          echo "âœ… í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ"
          
      - name: Commit and push if changed
        run: |
          git config --global user.name 'GitHub Actions'
          git config --global user.email 'actions@github.com'
          git add data/youtube_shorts_cache.json frontend/src/data/realData.json
          git diff --quiet && git diff --staged --quiet || (git commit -m "chore: ìë™ í¬ë¡¤ë§ ë°ì´í„° ì—…ë°ì´íŠ¸ [skip ci]" && git push)

