from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict
from shorts_planner import ShortsPlannerSystem
from youtube_trends import YouTubeTrendsAnalyzer
from youtube_realtime_crawler import YouTubeRealtimeCrawler
from youtube_shorts_crawler import YouTubeShortsCrawler
import json
from datetime import datetime
from pathlib import Path

app = FastAPI(
    title="ì‡¼ì¸  ì½˜í…ì¸  ê¸°íš ì‹œìŠ¤í…œ",
    description="ì¡°íšŒìˆ˜ ë†’ì€ ì‡¼ì¸  ì½˜í…ì¸ ë¥¼ ê¸°íší•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì‡¼ì¸  í”Œë˜ë„ˆ ì´ˆê¸°í™”
planner = ShortsPlannerSystem()
youtube_analyzer = YouTubeTrendsAnalyzer()
realtime_crawler = YouTubeRealtimeCrawler()
shorts_crawler = YouTubeShortsCrawler()

# ì„œë²„ ì‹œì‘ ì‹œ ì²« í¬ë¡¤ë§ ì‹¤í–‰
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰"""
    print("ğŸš€ ì„œë²„ ì‹œì‘ - Shorts í¬ë¡¤ë§ ì‹¤í–‰...")
    try:
        # Shorts ì „ìš© í¬ë¡¤ë§ - ì¹´í…Œê³ ë¦¬ë³„ ìµœì†Œ 10ê°œì”© ìˆ˜ì§‘
        shorts_videos = shorts_crawler.crawl_shorts_trending(200)
        shorts_crawler.save_to_cache(shorts_videos)
        print(f"âœ… Shorts í¬ë¡¤ë§ ì™„ë£Œ: {len(shorts_videos)}ê°œ")
    except Exception as e:
        print(f"âš ï¸ Shorts í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
    
    # ë°±ê·¸ë¼ìš´ë“œ ìë™ ì—…ë°ì´íŠ¸ ì‹œì‘ (ê¸°ì¡´ í¬ë¡¤ëŸ¬ë„ ìœ ì§€)
    realtime_crawler.start_background_update()

# Request/Response Models
class ContentPlanRequest(BaseModel):
    topic: str
    content_type: str = "Actionable"
    target_audience: Optional[str] = None
    user_story: Optional[Dict] = None

class ContentPlanResponse(BaseModel):
    plan: Dict
    generated_at: str

class NicheAnalysisRequest(BaseModel):
    topic: str
    target_audience: Optional[str] = None

class HookGenerationRequest(BaseModel):
    topic: str
    count: int = 10

class SavedPlan(BaseModel):
    id: str
    topic: str
    content_type: str
    plan: Dict
    created_at: str

# Storage file for saved plans
STORAGE_FILE = Path("../data/saved_plans.json")

def load_saved_plans() -> List[dict]:
    """ì €ì¥ëœ ê¸°íšì„œ ë¡œë“œ"""
    if STORAGE_FILE.exists():
        with open(STORAGE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def save_plan_to_file(plan: dict):
    """ê¸°íšì„œ ì €ì¥"""
    saved = load_saved_plans()
    saved.append(plan)
    
    STORAGE_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(STORAGE_FILE, 'w', encoding='utf-8') as f:
        json.dump(saved, f, ensure_ascii=False, indent=2)

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "ì‡¼ì¸  ì½˜í…ì¸  ê¸°íš ì‹œìŠ¤í…œ - ì¡°íšŒìˆ˜ ë†’ì€ ì½˜í…ì¸ ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”!",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.post("/api/create-plan", response_model=ContentPlanResponse)
async def create_content_plan(request: ContentPlanRequest):
    """ì½˜í…ì¸  ê¸°íšì„œ ìƒì„±"""
    try:
        plan = planner.create_content_plan(
            topic=request.topic,
            content_type=request.content_type,
            target_audience=request.target_audience or "",
            user_story=request.user_story
        )
        
        # ìƒì„± ì‹œê°„ ì¶”ê°€
        plan['ìƒì„±_ì¼ì‹œ'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        return ContentPlanResponse(
            plan=plan,
            generated_at=plan['ìƒì„±_ì¼ì‹œ']
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê¸°íšì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.post("/api/analyze-niche")
async def analyze_niche(request: NicheAnalysisRequest):
    """ë‹ˆì¹˜ ë¶„ì„"""
    try:
        analysis = planner.analyze_niche(
            topic=request.topic,
            target_audience=request.target_audience or ""
        )
        return {"analysis": analysis}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë‹ˆì¹˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/generate-hooks")
async def generate_hooks(request: HookGenerationRequest):
    """í›… ì•„ì´ë””ì–´ ìƒì„±"""
    try:
        hooks = planner.generate_hooks(
            topic=request.topic,
            count=request.count
        )
        return {"hooks": hooks}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í›… ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.get("/api/content-types")
async def get_content_types():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì½˜í…ì¸  íƒ€ì…"""
    content_types = [
        {
            "value": "Actionable",
            "label": "ì‹¤í–‰ ê°€ëŠ¥í•œ ê°€ì´ë“œ",
            "description": "ë‹¨ê³„ë³„ ë°©ë²• ì œì‹œ",
            "best_for": "íŠœí† ë¦¬ì–¼, í•˜ìš°íˆ¬"
        },
        {
            "value": "Motivational",
            "label": "ë™ê¸°ë¶€ì—¬ ìŠ¤í† ë¦¬",
            "description": "ì˜ê°ì„ ì£¼ëŠ” ì´ì•¼ê¸°",
            "best_for": "Before/After, ì„±ê³µ ìŠ¤í† ë¦¬"
        },
        {
            "value": "Analytical",
            "label": "ë¶„ì„ ë° í•´ë¶€",
            "description": "ì‹¬ì¸µ ë¶„ì„",
            "best_for": "ë¦¬ë·°, ë¹„êµ"
        },
        {
            "value": "Contrarian",
            "label": "ë°˜ëŒ€ ì˜ê²¬",
            "description": "ì¼ë°˜ ìƒì‹ì— ë„ì „",
            "best_for": "ë…¼ë€, í™”ì œì„±"
        },
        {
            "value": "Observation",
            "label": "ê´€ì°° ë° ì¸ì‚¬ì´íŠ¸",
            "description": "í¥ë¯¸ë¡œìš´ ë°œê²¬",
            "best_for": "íŠ¸ë Œë“œ, í˜„ìƒ ë¶„ì„"
        },
        {
            "value": "X vs. Y",
            "label": "ë¹„êµ ë¶„ì„",
            "description": "ë‘ ê°€ì§€ ë¹„êµ",
            "best_for": "ë¹„êµ, ëŒ€ê²°"
        },
        {
            "value": "Present/Future",
            "label": "í˜„ì¬ì™€ ë¯¸ë˜",
            "description": "íŠ¸ë Œë“œ ì˜ˆì¸¡",
            "best_for": "ì „ë§, ì˜ˆì¸¡"
        },
        {
            "value": "Listicle",
            "label": "ëª©ë¡í˜•",
            "description": "ë¦¬ìŠ¤íŠ¸ í˜•ì‹",
            "best_for": "TOP 10, ì¶”ì²œ"
        }
    ]
    return {"content_types": content_types}

@app.get("/api/trending-topics")
async def get_trending_topics():
    """íŠ¸ë Œë”© ì£¼ì œ ì¶”ì²œ"""
    try:
        topics = planner.get_trending_topics()
        return {"trending_topics": topics}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŠ¸ë Œë”© ì£¼ì œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/suggest-hashtags")
async def suggest_hashtags(request: dict):
    """í•´ì‹œíƒœê·¸ ì œì•ˆ"""
    try:
        topic = request.get("topic", "")
        category = request.get("category", "")
        
        hashtags = planner.suggest_hashtags(topic, category)
        return {"hashtags": hashtags}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í•´ì‹œíƒœê·¸ ì œì•ˆ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/save-plan")
async def save_plan(content: dict):
    """ê¸°íšì„œ ì €ì¥"""
    try:
        plan_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_item = {
            "id": plan_id,
            "topic": content.get("topic"),
            "content_type": content.get("content_type"),
            "plan": content.get("plan"),
            "created_at": datetime.now().isoformat()
        }
        
        save_plan_to_file(saved_item)
        
        return {"message": "ê¸°íšì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤", "id": plan_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê¸°íšì„œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/saved-plans")
async def get_saved_plans():
    """ì €ì¥ëœ ê¸°íšì„œ ëª©ë¡"""
    try:
        saved = load_saved_plans()
        return {"saved_plans": saved, "count": len(saved)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê¸°íšì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.delete("/api/saved-plans/{plan_id}")
async def delete_saved_plan(plan_id: str):
    """ê¸°íšì„œ ì‚­ì œ"""
    try:
        saved = load_saved_plans()
        saved = [item for item in saved if item.get('id') != plan_id]
        
        with open(STORAGE_FILE, 'w', encoding='utf-8') as f:
            json.dump(saved, f, ensure_ascii=False, indent=2)
        
        return {"message": "ê¸°íšì„œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê¸°íšì„œ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/optimization-checklist")
async def get_optimization_checklist():
    """ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸"""
    checklist = planner.system_data.get("ì‡¼ì¸ _ìµœì í™”", {})
    return {
        "checklist": checklist.get("ì¡°íšŒìˆ˜_ìµœì í™”_ì²´í¬ë¦¬ìŠ¤íŠ¸", []),
        "viral_elements": checklist.get("ë°”ì´ëŸ´_ìš”ì†Œ", []),
        "platforms": checklist.get("í”Œë«í¼ë³„_ì „ëµ", {})
    }

@app.get("/api/youtube/trending")
async def get_youtube_trending(
    count: int = 20,
    category: Optional[str] = None,
    region: Optional[str] = None,
    language: Optional[str] = None,
    min_trend_score: Optional[int] = None,
    sort_by: str = "trend_score",
    force_refresh: bool = False
):
    """YouTube Shorts ê¸‰ìƒìŠ¹ ë™ì˜ìƒ (í•„í„°ë§ ì§€ì›)"""
    try:
        # force_refreshê°€ Trueì´ê±°ë‚˜ ìºì‹œê°€ ì˜¤ë˜ëœ ê²½ìš° ìƒˆë¡œ í¬ë¡¤ë§
        cache_file = Path("../data/youtube_shorts_cache.json")
        should_refresh = force_refresh
        
        if cache_file.exists():
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache = json.load(f)
            
            # ìºì‹œê°€ 1ì‹œê°„ ì´ìƒ ì˜¤ë˜ëœ ê²½ìš°ì—ë§Œ ìƒˆë¡œê³ ì¹¨
            if cache.get('last_updated'):
                last_updated = datetime.fromisoformat(cache['last_updated'].replace('Z', '+00:00'))
                time_diff = (datetime.now() - last_updated).total_seconds()
                if time_diff > 3600:  # 1ì‹œê°„
                    should_refresh = True
                    print(f"ğŸ”„ ìºì‹œê°€ {int(time_diff/3600)}ì‹œê°„ ì „ ë°ì´í„° - ìƒˆë¡œê³ ì¹¨")
        
        if should_refresh or not cache_file.exists():
            print("ğŸ”„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìµœì‹  ë°ì´í„° í¬ë¡¤ë§ ì¤‘...")
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í¬ë¡¤ë§ ì‹œì‘ (ê¸°ì¡´ ë°ì´í„° ë¨¼ì € ë°˜í™˜)
            import threading
            def background_crawl():
                try:
                    videos = shorts_crawler.crawl_shorts_trending(200)
                    shorts_crawler.save_to_cache(videos)
                    print("âœ… ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì™„ë£Œ")
                except Exception as e:
                    print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            
            threading.Thread(target=background_crawl, daemon=True).start()
            
            # ê¸°ì¡´ ìºì‹œê°€ ìˆìœ¼ë©´ ë¨¼ì € ë°˜í™˜
            if cache and cache.get('videos'):
                print("ğŸ“Š ê¸°ì¡´ ë°ì´í„° ë¨¼ì € ë°˜í™˜, ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì—…ë°ì´íŠ¸ ì¤‘...")
            else:
                # ìºì‹œê°€ ì—†ìœ¼ë©´ ì¦‰ì‹œ í¬ë¡¤ë§
                videos = shorts_crawler.crawl_shorts_trending(200)
                shorts_crawler.save_to_cache(videos)
                cache = {"videos": videos, "last_updated": datetime.now().isoformat()}
        
        if cache and cache.get('videos'):
            videos = cache['videos']
            
            # í•„í„°ë§ ì ìš©
            filtered_videos = _apply_filters(videos, category, region, language, min_trend_score)
            
            # ì •ë ¬
            sorted_videos = _sort_videos(filtered_videos, sort_by)
            
            # ê°œìˆ˜ ì œí•œ
            final_videos = sorted_videos[:count]
            
            return {
                "trending_videos": final_videos,
                "count": len(final_videos),
                "total_count": len(filtered_videos),
                "filters_applied": {
                    "category": category,
                    "region": region,
                    "language": language,
                    "min_trend_score": min_trend_score,
                    "sort_by": sort_by
                },
                "last_updated": cache.get('last_updated'),
                "source": "shorts_cache",
                "auto_refreshed": should_refresh
            }
        
        # ìºì‹œ ì—†ìœ¼ë©´ ì¦‰ì‹œ Shorts í¬ë¡¤ë§
        print("Shorts ìºì‹œ ì—†ìŒ - ì¦‰ì‹œ í¬ë¡¤ë§ ì‹¤í–‰")
        videos = shorts_crawler.crawl_shorts_trending(count)
        shorts_crawler.save_to_cache(videos)
        
        return {
            "trending_videos": videos,
            "count": len(videos),
            "last_updated": datetime.now().isoformat(),
            "source": "fresh_shorts_crawl"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Shorts íŠ¸ë Œë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

def _apply_filters(videos: List[Dict], category: Optional[str], region: Optional[str], 
                  language: Optional[str], min_trend_score: Optional[int]) -> List[Dict]:
    """ë¹„ë””ì˜¤ í•„í„°ë§"""
    filtered = videos
    
    if category:
        filtered = [v for v in filtered if v.get('category') == category]
    
    if region:
        filtered = [v for v in filtered if v.get('region') == region]
    
    if language:
        filtered = [v for v in filtered if v.get('language') == language]
    
    if min_trend_score:
        filtered = [v for v in filtered if v.get('trend_score', 0) >= min_trend_score]
    
    return filtered

def _sort_videos(videos: List[Dict], sort_by: str) -> List[Dict]:
    """ë¹„ë””ì˜¤ ì •ë ¬"""
    if sort_by == "trend_score":
        return sorted(videos, key=lambda x: x.get('trend_score', 0), reverse=True)
    elif sort_by == "views":
        # ì¡°íšŒìˆ˜ ì •ë ¬ (K, M ì²˜ë¦¬)
        def parse_views(views_str):
            if 'M' in views_str:
                return float(views_str.replace('M', '')) * 1000000
            elif 'K' in views_str:
                return float(views_str.replace('K', '')) * 1000
            else:
                try:
                    return float(views_str.replace(',', ''))
                except:
                    return 0
        return sorted(videos, key=lambda x: parse_views(x.get('views', '0')), reverse=True)
    elif sort_by == "crawled_at":
        return sorted(videos, key=lambda x: x.get('crawled_at', ''), reverse=True)
    else:
        return videos

@app.post("/api/youtube/refresh")
async def refresh_youtube_trending():
    """ìµœì‹  ë°ì´í„°ë¡œ ê°•ì œ ì—…ë°ì´íŠ¸ - ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì™„ë£Œ í›„ ì‚¬ìš©"""
    try:
        print("ğŸ”„ ìµœì‹  ë°ì´í„° í™•ì¸ ì¤‘...")
        
        cache_file = Path("../data/youtube_shorts_cache.json")
        if cache_file.exists():
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache = json.load(f)
            
            # ìºì‹œê°€ ìµœê·¼ 10ë¶„ ì´ë‚´ë©´ ìµœì‹  ë°ì´í„°
            if cache.get('last_updated'):
                last_updated = datetime.fromisoformat(cache['last_updated'].replace('Z', '+00:00'))
                time_diff = (datetime.now() - last_updated).total_seconds()
                if time_diff < 600:  # 10ë¶„ ì´ë‚´
                    print("âœ… ì´ë¯¸ ìµœì‹  ë°ì´í„°ì…ë‹ˆë‹¤")
                    return {
                        "message": "ì´ë¯¸ ìµœì‹  ë°ì´í„°ì…ë‹ˆë‹¤",
                        "last_updated": cache['last_updated'],
                        "count": len(cache.get('videos', [])),
                        "source": "cached_data",
                        "status": "already_fresh"
                    }
        
        # ìµœì‹  ë°ì´í„°ê°€ ì•„ë‹ˆë©´ ê°•ì œ í¬ë¡¤ë§
        print("ğŸ”„ ìµœì‹  ë°ì´í„° í¬ë¡¤ë§ ì¤‘...")
        videos = shorts_crawler.crawl_shorts_trending(200)
        shorts_crawler.save_to_cache(videos)
        
        print(f"âœ… ìµœì‹  ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(videos)}ê°œ ë™ì˜ìƒ")
        
        return {
            "message": "ìµœì‹  ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ ì™„ë£Œ",
            "last_updated": datetime.now().isoformat(),
            "count": len(videos),
            "source": "fresh_crawl",
            "status": "success"
        }
    except Exception as e:
        print(f"âŒ ìµœì‹  ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/youtube/category-keywords/{category}")
async def get_category_keywords(category: str):
    """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ í•« í‚¤ì›Œë“œ ë¶„ì„"""
    try:
        # ìºì‹œì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì˜ìƒë“¤ ê°€ì ¸ì˜¤ê¸°
        cache_file = Path("../data/youtube_shorts_cache.json")
        if not cache_file.exists():
            raise HTTPException(status_code=404, detail="ìºì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            
        with open(cache_file, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
        
        category_videos = [v for v in cache_data.get('videos', []) if v.get('category') == category]
        
        if not category_videos:
            return {
                "category": category,
                "keywords": [],
                "message": f"{category} ì¹´í…Œê³ ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            }
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¶„ì„
        all_keywords = []
        for video in category_videos:
            all_keywords.extend(video.get('keywords', []))
        
        # í‚¤ì›Œë“œ ë¹ˆë„ ê³„ì‚°
        from collections import Counter
        keyword_counts = Counter(all_keywords)
        
        # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
        top_keywords = []
        for keyword, count in keyword_counts.most_common(20):
            if keyword and len(keyword) > 1:  # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ 1ê¸€ì í‚¤ì›Œë“œ ì œì™¸
                top_keywords.append({
                    "keyword": keyword,
                    "frequency": count,
                    "percentage": round((count / len(category_videos)) * 100, 1)
                })
        
        return {
            "category": category,
            "total_videos": len(category_videos),
            "keywords": top_keywords,
            "last_updated": cache_data.get('last_updated', datetime.now().isoformat())
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/youtube/filter-options")
async def get_filter_options():
    """ì‚¬ìš© ê°€ëŠ¥í•œ í•„í„° ì˜µì…˜ ì œê³µ"""
    try:
        cache_file = Path("../data/youtube_shorts_cache.json")
        if cache_file.exists():
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache = json.load(f)
            
            if cache and cache.get('videos'):
                videos = cache['videos']
                
                # ì‹¤ì œ ë°ì´í„°ì—ì„œ ë°œê²¬ëœ ì¹´í…Œê³ ë¦¬
                found_categories = list(set(v.get('category', '') for v in videos if v.get('category')))
                
                # ì „ì²´ YouTube ì¹´í…Œê³ ë¦¬ ëª©ë¡
                all_categories = [
                    "ì˜í™”/ì• ë‹ˆë©”ì´ì…˜", "ìë™ì°¨/ì°¨ëŸ‰", "ìŒì•…", "ë°˜ë ¤ë™ë¬¼/ë™ë¬¼", "ìŠ¤í¬ì¸ ",
                    "ì—¬í–‰/ì´ë²¤íŠ¸", "ê²Œì„", "ì¸ë¬¼/ë¸”ë¡œê·¸", "ì½”ë¯¸ë””", "ì—”í„°í…Œì¸ë¨¼íŠ¸",
                    "ë‰´ìŠ¤/ì •ì¹˜", "ë…¸í•˜ìš°/ìŠ¤íƒ€ì¼", "êµìœ¡", "ê³¼í•™ê¸°ìˆ ", "ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™",
                    "ìš”ë¦¬/ìŒì‹", "ìê¸°ê³„ë°œ", "ì¬í…Œí¬/ê¸ˆìœµ", "ì°½ì—…/ë¶€ì—…", "ë§ˆì¼€íŒ…/ë¹„ì¦ˆë‹ˆìŠ¤", "ì¼ë°˜"
                ]
                
                # ë°œê²¬ëœ ì¹´í…Œê³ ë¦¬ì™€ ì „ì²´ ì¹´í…Œê³ ë¦¬ ê²°í•© (ì¤‘ë³µ ì œê±°)
                categories = sorted(list(set(found_categories + all_categories)))
                
                # ì§€ì—­ ì˜µì…˜
                regions = list(set(v.get('region', '') for v in videos if v.get('region')))
                
                # ì–¸ì–´ ì˜µì…˜
                languages = list(set(v.get('language', '') for v in videos if v.get('language')))
                
                # ì •ë ¬ ì˜µì…˜
                sort_options = [
                    {"value": "trend_score", "label": "íŠ¸ë Œë“œ ì ìˆ˜"},
                    {"value": "views", "label": "ì¡°íšŒìˆ˜"},
                    {"value": "crawled_at", "label": "ìµœì‹ ìˆœ"}
                ]
                
                return {
                    "categories": sorted(categories),
                    "regions": sorted(regions),
                    "languages": sorted(languages),
                    "sort_options": sort_options,
                    "trend_score_range": {
                        "min": 1,
                        "max": 100,
                        "default": 50
                    }
                }
        
        # ê¸°ë³¸ ì˜µì…˜ ë°˜í™˜
        return {
            "categories": [
                "ì˜í™”/ì• ë‹ˆë©”ì´ì…˜",
                "ìë™ì°¨/ì°¨ëŸ‰",
                "ìŒì•…",
                "ë°˜ë ¤ë™ë¬¼/ë™ë¬¼",
                "ìŠ¤í¬ì¸ ",
                "ì—¬í–‰/ì´ë²¤íŠ¸",
                "ê²Œì„",
                "ì¸ë¬¼/ë¸”ë¡œê·¸",
                "ì½”ë¯¸ë””",
                "ì—”í„°í…Œì¸ë¨¼íŠ¸",
                "ë‰´ìŠ¤/ì •ì¹˜",
                "ë…¸í•˜ìš°/ìŠ¤íƒ€ì¼",
                "êµìœ¡",
                "ê³¼í•™ê¸°ìˆ ",
                "ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™",
                "ìš”ë¦¬/ìŒì‹",
                "ìê¸°ê³„ë°œ",
                "ì¬í…Œí¬/ê¸ˆìœµ",
                "ì°½ì—…/ë¶€ì—…",
                "ë§ˆì¼€íŒ…/ë¹„ì¦ˆë‹ˆìŠ¤",
                "ì¼ë°˜"
            ],
            "regions": ["êµ­ë‚´", "í•´ì™¸"],
            "languages": ["í•œêµ­ì–´", "ì˜ì–´"],
            "sort_options": [
                {"value": "trend_score", "label": "íŠ¸ë Œë“œ ì ìˆ˜"},
                {"value": "views", "label": "ì¡°íšŒìˆ˜"},
                {"value": "crawled_at", "label": "ìµœì‹ ìˆœ"}
            ],
            "trend_score_range": {
                "min": 1,
                "max": 100,
                "default": 50
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í•„í„° ì˜µì…˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/youtube/analyze-keywords")
async def analyze_keywords(request: dict):
    """ê¸‰ìƒìŠ¹ ë™ì˜ìƒì—ì„œ í‚¤ì›Œë“œ ë¶„ì„"""
    try:
        videos = request.get("videos", [])
        if not videos:
            videos = youtube_analyzer.get_trending_videos(20)
        
        analysis = youtube_analyzer.extract_keywords_from_videos(videos)
        return {"keyword_analysis": analysis}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í‚¤ì›Œë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/youtube/content-ideas")
async def get_content_ideas(request: dict):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì½˜í…ì¸  ì•„ì´ë””ì–´"""
    try:
        keyword = request.get("keyword", "")
        videos = youtube_analyzer.get_trending_videos(20)
        
        ideas = youtube_analyzer.suggest_content_ideas(keyword, videos)
        return {"content_ideas": ideas}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì•„ì´ë””ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.get("/api/youtube/posting-times")
async def get_posting_times():
    """ìµœì  ì—…ë¡œë“œ ì‹œê°„"""
    try:
        times = youtube_analyzer.get_optimal_posting_times()
        return {"posting_times": times}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì‹œê°„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "system_loaded": bool(planner.system_data),
        "youtube_analyzer_loaded": youtube_analyzer is not None
    }

if __name__ == "__main__":
    import uvicorn
    import os
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
