"""
Methodus Shorts Planner - YouTube Data API v3 ë°±ì—”ë“œ
YouTube ë°ì´í„°ë¥¼ ê³µì‹ APIë¥¼ í†µí•´ ì œê³µ
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict
import json
from datetime import datetime
from pathlib import Path
import os
import threading
import time
from youtube_api_service import YouTubeAPIService
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# GeminiëŠ” ì„ íƒì ìœ¼ë¡œ import
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (AI ê¸°ëŠ¥ ë¹„í™œì„±í™”)")

app = FastAPI(
    title="Methodus Shorts Planner API",
    description="YouTube ê¸‰ìƒìŠ¹ ì˜ìƒ ë¶„ì„ API - YouTube Data API v3",
    version="3.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ê°„ë‹¨í•œ ë°ì´í„° ëª¨ë¸
class TrendingVideo(BaseModel):
    title: str
    views: str
    category: str
    language: str
    video_type: str
    youtube_url: str
    thumbnail: str
    trend_score: int
    crawled_at: str
    published_at: Optional[str] = None  # ì˜ìƒ ì—…ë¡œë“œ ë‚ ì§œ
    region: Optional[str] = None
    keywords: Optional[List[str]] = None
    why_viral: Optional[str] = None
    engagement: Optional[str] = None

class TrendingVideosResponse(BaseModel):
    trending_videos: List[TrendingVideo]
    count: int
    total_count: int
    last_updated: str
    source: str

# í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
# crawler = SimpleYouTubeCrawler()

# YouTube API ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
try:
    youtube_service = YouTubeAPIService()
    print("âœ… YouTube API ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
except ValueError as e:
    print(f"âš ï¸ YouTube API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    print("ğŸ’¡ .env íŒŒì¼ì— YOUTUBE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    print("   ì„¤ì • ë°©ë²•ì€ YOUTUBE_API_SETUP.mdë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.")
    youtube_service = None

# Google Gemini ì´ˆê¸°í™” (ì„ íƒì )
gemini_api_key = os.getenv("GEMINI_API_KEY")
gemini_model = None
if GEMINI_AVAILABLE and gemini_api_key:
    try:
        genai.configure(api_key=gemini_api_key)
        gemini_model = genai.GenerativeModel('gemini-2.0-flash')
        print("âœ… Google Gemini 2.0 Flash ì´ˆê¸°í™” ì™„ë£Œ (ë¬´ë£Œ!)")
    except Exception as e:
        print(f"âš ï¸ Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        gemini_model = None
elif not GEMINI_AVAILABLE:
    print("âš ï¸ Gemini AI íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤ (ê¸°ë³¸ íŒ¨í„´ ì‚¬ìš©)")
else:
    print("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

# ìºì‹œëœ ë°ì´í„° ì €ì¥ì†Œ
cached_videos = []
last_update_time = None

def save_cache_to_file(videos):
    """ìºì‹œ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        cache_data = {
            'videos': videos,
            'last_updated': datetime.now().isoformat(),
            'count': len(videos)
        }
        
        cache_file = Path('video_cache.json')
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ìºì‹œ ì €ì¥ ì™„ë£Œ: {len(videos)}ê°œ ì˜ìƒ")
        return True
    except Exception as e:
        print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_cache_from_file():
    """íŒŒì¼ì—ì„œ ìºì‹œ ë°ì´í„° ë¡œë“œ"""
    try:
        cache_file = Path('video_cache.json')
        if cache_file.exists():
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            return cache_data.get('videos', []), cache_data.get('last_updated')
    except Exception as e:
        print(f"âŒ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return [], None

def fetch_youtube_data():
    """YouTube APIë¥¼ í†µí•´ ë°ì´í„° ìˆ˜ì§‘"""
    global cached_videos, last_update_time
    
    if not youtube_service:
        print("âŒ YouTube API ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        print(f"ğŸ”„ [{datetime.now().strftime('%H:%M:%S')}] YouTube API ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì—¬ëŸ¬ ì§€ì—­ì—ì„œ ì¢…í•© ë°ì´í„° ìˆ˜ì§‘
        videos = youtube_service.get_comprehensive_data(
            region_codes=['KR', 'US', 'JP'],  # í•œêµ­, ë¯¸êµ­, ì¼ë³¸
            min_videos_per_category=100
        )
        
        if videos and len(videos) > 0:
            cached_videos = videos
            last_update_time = datetime.now().isoformat()
            
            # ìºì‹œ ì €ì¥
            save_cache_to_file(videos)
            
            print(f"âœ… YouTube API ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(videos)}ê°œ ì˜ìƒ")
            return True
        else:
            print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
            
    except Exception as e:
        print(f"âŒ YouTube API ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return False

# ìë™ ë°ì´í„° ìˆ˜ì§‘ ì„¤ì • (2ì‹œê°„ë§ˆë‹¤)
def auto_fetch_loop():
    """2ì‹œê°„ë§ˆë‹¤ ìë™ìœ¼ë¡œ YouTube ë°ì´í„° ìˆ˜ì§‘"""
    while True:
        time.sleep(2 * 60 * 60)  # 2ì‹œê°„
        fetch_youtube_data()

# ì´ˆê¸° ë°ì´í„° ë¡œë“œ
print("ğŸ”„ ì´ˆê¸° ë°ì´í„° ë¡œë“œ ì¤‘...")
cached_videos, last_update_time = load_cache_from_file()

# ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¦‰ì‹œ ìˆ˜ì§‘
if not cached_videos and youtube_service:
    print("ğŸ“¡ ìºì‹œëœ ë°ì´í„°ê°€ ì—†ì–´ì„œ ì¦‰ì‹œ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    fetch_youtube_data()

# ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìë™ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘
if youtube_service:
    threading.Thread(target=auto_fetch_loop, daemon=True).start()
    print("âœ… ìë™ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ë ˆë“œ ì‹œì‘ (2ì‹œê°„ ê°„ê²©)")

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "Methodus Shorts Planner API - YouTube Data API v3",
        "version": "3.0.0",
        "status": "running",
        "api_status": "active" if youtube_service else "not_configured",
        "docs": "/docs",
        "setup_guide": "YOUTUBE_API_SETUP.md"
    }

@app.get("/api/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "methodus-shorts-planner",
        "version": "3.0.0",
        "youtube_api": "active" if youtube_service else "not_configured",
        "cached_videos": len(cached_videos) if cached_videos else 0,
        "last_update": last_update_time
    }

@app.get("/api/youtube/trending", response_model=TrendingVideosResponse)
async def get_youtube_trending(
    count: int = 20,
    category: Optional[str] = None,
    region: Optional[str] = None,
    language: Optional[str] = None,
    min_trend_score: Optional[int] = None,
    sort_by: str = "trend_score",
    video_type: Optional[str] = None,
    time_filter: Optional[str] = None
):
    """YouTube ê¸‰ìƒìŠ¹ ë™ì˜ìƒ ì¡°íšŒ (YouTube Data API v3)"""
    global cached_videos, last_update_time
    
    try:
        # ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¦‰ì‹œ ìˆ˜ì§‘
        if not cached_videos and youtube_service:
            print("ğŸ“¡ ìºì‹œëœ ë°ì´í„°ê°€ ì—†ì–´ì„œ ì¦‰ì‹œ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            fetch_youtube_data()
        
        # ìºì‹œëœ ë°ì´í„° ì‚¬ìš©
        cached_videos = cached_videos if cached_videos else []
        
        if not cached_videos or len(cached_videos) == 0:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ì‘ë‹µ ë°˜í™˜
            return TrendingVideosResponse(
                trending_videos=[],
                count=0,
                total_count=0,
                last_updated=datetime.now().isoformat(),
                source="no_data"
            )
        
        # í•„í„°ë§ ì ìš©
        filtered_videos = cached_videos.copy()
        
        # ì¹´í…Œê³ ë¦¬ í•„í„°
        if category:
            filtered_videos = [v for v in filtered_videos if v.get('category') == category]
        
        # ì–¸ì–´ í•„í„°
        if language:
            filtered_videos = [v for v in filtered_videos if v.get('language') == language]
        
        # ì˜ìƒ íƒ€ì… í•„í„°
        if video_type:
            if video_type == 'shorts':
                video_type_filter = 'ì‡¼ì¸ '
            elif video_type == 'long':
                video_type_filter = 'ë¡±í¼'
            else:
                video_type_filter = video_type
            filtered_videos = [v for v in filtered_videos if v.get('video_type') == video_type_filter]
        
        # ì§€ì—­ í•„í„°
        if region:
            filtered_videos = [v for v in filtered_videos if v.get('region') == region]
        
        # íŠ¸ë Œë“œ ì ìˆ˜ í•„í„°
        if min_trend_score:
            filtered_videos = [v for v in filtered_videos if v.get('trend_score', 0) >= min_trend_score]
        
        # ì •ë ¬ (í•œêµ­ì–´ ì½˜í…ì¸  ìš°ì„ )
        if sort_by == "trend_score":
            # í•œêµ­ì–´ ì½˜í…ì¸ ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì •ë ¬
            filtered_videos.sort(key=lambda x: (
                x.get('language') != 'í•œêµ­ì–´',  # í•œêµ­ì–´ê°€ ì•„ë‹ˆë©´ True (ë’¤ë¡œ)
                -x.get('trend_score', 0)  # íŠ¸ë Œë“œ ì ìˆ˜ ë†’ì€ ìˆœ
            ))
        elif sort_by == "views":
            def parse_views(views_str):
                if 'M' in str(views_str):
                    return float(str(views_str).replace('M', '')) * 1000000
                elif 'K' in str(views_str):
                    return float(str(views_str).replace('K', '')) * 1000
                else:
                    try:
                        return float(str(views_str).replace(',', ''))
                    except:
                        return 0
            filtered_videos.sort(key=lambda x: parse_views(x.get('views', '0')), reverse=True)
        elif sort_by == "crawled_at":
            filtered_videos.sort(key=lambda x: x.get('crawled_at', ''), reverse=True)
        
        # ê°œìˆ˜ ì œí•œ
        final_videos = filtered_videos[:count]
        
        return TrendingVideosResponse(
            trending_videos=final_videos,
            count=len(final_videos),
            total_count=len(filtered_videos),
            last_updated=last_update_time or datetime.now().isoformat(),
            source="youtube_api_v3"
        )
        
    except Exception as e:
        print(f"âŒ ì˜ìƒ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì˜ìƒ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/youtube/filter-options")
async def get_filter_options():
    """ì‚¬ìš© ê°€ëŠ¥í•œ í•„í„° ì˜µì…˜ ì œê³µ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)"""
    # ì‹¤ì œ ìºì‹œëœ ë°ì´í„°ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    unique_categories = set()
    if cached_videos:
        for video in cached_videos:
            cat = video.get('category')
            if cat:
                unique_categories.add(cat)
    
    return {
        "categories": sorted(list(unique_categories)) if unique_categories else [
            "ë§ˆì¼€íŒ…/ë¹„ì¦ˆë‹ˆìŠ¤", "ê²Œì„", "ì¬í…Œí¬/ê¸ˆìœµ", "ìŒì•…", "ìš´ë™/ê±´ê°•",
            "ìê¸°ê³„ë°œ", "ê³¼í•™ê¸°ìˆ ", "ì—”í„°í…Œì¸ë¨¼íŠ¸", "êµìœ¡/í•™ìŠµ", "ê¸°íƒ€"
        ],
        "regions": ["êµ­ë‚´", "í•´ì™¸"],
        "languages": ["í•œêµ­ì–´", "ì˜ì–´"],
        "sort_options": [
            {"value": "trend_score", "label": "íŠ¸ë Œë“œ ì ìˆ˜"},
            {"value": "views", "label": "ì¡°íšŒìˆ˜"},
            {"value": "crawled_at", "label": "ìµœì‹ ìˆœ"}
        ],
        "trend_score_range": {
            "min": 1,
            "max": 100,
            "default": 50
        }
    }

@app.post("/api/ai/generate-title-patterns")
async def generate_title_patterns(request: dict):
    """Google Gemini AIë¥¼ ì‚¬ìš©í•´ì„œ í‚¤ì›Œë“œì— ë§ëŠ” ì œëª© íŒ¨í„´ ìƒì„±"""
    keyword = request.get('keyword', '')
    related_videos = request.get('related_videos', [])
    
    if not gemini_model:
        # Geminiê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ íŒ¨í„´ ë°˜í™˜
        return {
            "title_patterns": [
                f"{keyword} ì™„ë²½ ê°€ì´ë“œ",
                f"{keyword} í•µì‹¬ ì •ë¦¬",
                f"{keyword} ì‹¤ì „ í™œìš©ë²•",
                f"{keyword} íŠ¸ë Œë“œ ë¶„ì„"
            ],
            "source": "default"
        }
    
    try:
        # ê´€ë ¨ ì˜ìƒ ì œëª©ë“¤ì„ ë¬¸ë§¥ìœ¼ë¡œ ì œê³µ
        video_titles_context = "\n".join([f"- {v['title']}" for v in related_videos[:10]]) if related_videos else "ê´€ë ¨ ì˜ìƒ ì—†ìŒ"
        
        # Google Geminië¡œ ë§ì¶¤í˜• ì œëª© íŒ¨í„´ ìƒì„±
        prompt = f"""ë‹¤ìŒì€ YouTubeì—ì„œ ê¸‰ìƒìŠ¹ ì¤‘ì¸ '{keyword}' ê´€ë ¨ ì˜ìƒë“¤ì…ë‹ˆë‹¤:

{video_titles_context}

ìœ„ ì˜ìƒë“¤ì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬, '{keyword}'ë¥¼ í™œìš©í•œ ìœ íŠœë¸Œ ì½˜í…ì¸  ì œëª©ì„ 4ê°œë§Œ ìƒì„±í•´ì£¼ì„¸ìš”.

ì¤‘ìš” ê·œì¹™:
1. ì‹¤ì œ ê¸‰ìƒìŠ¹ ì˜ìƒë“¤ì˜ ìŠ¤íƒ€ì¼ê³¼ íŒ¨í„´ì„ ì •í™•íˆ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤
2. í‚¤ì›Œë“œê°€ ì¸ë¬¼ëª…(ì—°ì˜ˆì¸, ìœ ëª…ì¸)ì´ë©´ ì¸ë¬¼ ê´€ë ¨ ì½˜í…ì¸ ë§Œ (ê·¼í™©, ë¬´ëŒ€, ì¸í„°ë·°, í™”ì œì˜ ìˆœê°„)
3. í‚¤ì›Œë“œê°€ ê¸°ìˆ /ë„êµ¬ë©´ ì‚¬ìš©ë²•, ê°€ì´ë“œ í˜•ì‹
4. í‚¤ì›Œë“œê°€ ì¼ë°˜ ì£¼ì œë©´ ì •ë³´/íŒ í˜•ì‹
5. "~ë¡œ ëˆ ë²„ëŠ” ë°©ë²•" ê°™ì€ ë»”í•˜ê³  ë¶€ì ì ˆí•œ íŒ¨í„´ì€ ì ˆëŒ€ ê¸ˆì§€
6. ê° ì œëª©ì€ ê°„ê²°í•˜ê³  í´ë¦­ì„ ìœ ë„í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ
7. ì¸ë¬¼ëª…ì— ë¹„ì¦ˆë‹ˆìŠ¤/ëˆ ê´€ë ¨ ë‹¨ì–´ë¥¼ ì¡°í•©í•˜ì§€ ë§ˆì„¸ìš”

ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ:
{{"titles": ["ì œëª©1", "ì œëª©2", "ì œëª©3", "ì œëª©4"]}}"""

        response = gemini_model.generate_content(prompt)
        result_text = response.text.strip()
        
        # JSON íŒŒì‹± (ì½”ë“œ ë¸”ë¡ ì œê±°)
        import json
        import re
        
        # ```json ... ``` í˜•ì‹ì´ë©´ ì œê±°
        json_match = re.search(r'```json\s*(.*?)\s*```', result_text, re.DOTALL)
        if json_match:
            result_text = json_match.group(1)
        elif '```' in result_text:
            result_text = result_text.replace('```', '')
        
        result = json.loads(result_text)
        
        return {
            "title_patterns": result.get("titles", []),
            "source": "gemini_ai"
        }
        
    except Exception as e:
        print(f"âŒ Gemini ì œëª© ìƒì„± ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ì‹¤ì œ ì˜ìƒ ì œëª© ì‚¬ìš©
        if related_videos and len(related_videos) > 0:
            return {
                "title_patterns": [v['title'] for v in related_videos[:4]],
                "source": "related_videos"
            }
        return {
            "title_patterns": [
                f"{keyword} ì™„ë²½ ê°€ì´ë“œ",
                f"{keyword} í•µì‹¬ ì •ë¦¬",
                f"{keyword} ì‹¤ì „ í™œìš©ë²•",
                f"{keyword} íŠ¸ë Œë“œ ë¶„ì„"
            ],
            "source": "fallback"
        }

@app.post("/api/youtube/force-refresh")
async def force_refresh():
    """ê°•ì œ ìƒˆë¡œê³ ì¹¨ - ì¦‰ì‹œ YouTube APIë¡œ ë°ì´í„° ìˆ˜ì§‘"""
    if not youtube_service:
        raise HTTPException(
            status_code=503,
            detail="YouTube APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— YOUTUBE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”."
        )
    
    try:
        print("ğŸ”„ ê°•ì œ ìƒˆë¡œê³ ì¹¨ ìš”ì²­...")
        
        success = fetch_youtube_data()
        
        if success:
            return {
                "success": True,
                "message": f"ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ: {len(cached_videos)}ê°œ ì˜ìƒ ì—…ë°ì´íŠ¸",
                "timestamp": datetime.now().isoformat(),
                "source": "youtube_api_v3"
            }
        else:
            return {
                "success": False,
                "message": "ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨",
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        print(f"âŒ ê°•ì œ ìƒˆë¡œê³ ì¹¨ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)

# Renderìš© Gunicorn ì„¤ì •
if __name__ != "__main__":
    import gunicorn.app.wsgiapp as wsgi
    wsgi.run()