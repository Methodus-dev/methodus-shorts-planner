"""
YouTube Data API v3 ì„œë¹„ìŠ¤
ê¸‰ìƒìŠ¹ ì˜ìƒ ë°ì´í„°ë¥¼ YouTube ê³µì‹ APIë¥¼ í†µí•´ ìˆ˜ì§‘
"""
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from typing import List, Dict, Optional
from datetime import datetime, timedelta
import random
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class YouTubeAPIService:
    """YouTube Data API v3ë¥¼ ì‚¬ìš©í•œ ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        YouTube API ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            api_key: YouTube Data API v3 í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        """
        self.api_key = api_key or os.getenv('YOUTUBE_API_KEY')
        
        if not self.api_key:
            raise ValueError(
                "YouTube API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                "í™˜ê²½ ë³€ìˆ˜ YOUTUBE_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_key íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì„¸ìš”. "
                "ì„¤ì • ë°©ë²•ì€ YOUTUBE_API_SETUP.md íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”."
            )
        
        # YouTube API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        self.youtube = build('youtube', 'v3', developerKey=self.api_key)
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (YouTube ì¹´í…Œê³ ë¦¬ ID â†’ í•œêµ­ì–´ ì¹´í…Œê³ ë¦¬ëª…)
        self.category_mapping = {
            '1': 'ì˜í™”/ì• ë‹ˆë©”ì´ì…˜',
            '2': 'ìë™ì°¨/êµí†µ',
            '10': 'ìŒì•…',
            '15': 'ë™ë¬¼/ë°˜ë ¤ë™ë¬¼',
            '17': 'ìŠ¤í¬ì¸ ',
            '19': 'ì—¬í–‰/ì´ë²¤íŠ¸',
            '20': 'ê²Œì„',
            '22': 'ì‚¬ëŒ/ë¸”ë¡œê·¸',
            '23': 'ì½”ë¯¸ë””',
            '24': 'ì—”í„°í…Œì¸ë¨¼íŠ¸',
            '25': 'ë‰´ìŠ¤/ì •ì¹˜',
            '26': 'ë¼ì´í”„ìŠ¤íƒ€ì¼',
            '27': 'êµìœ¡/í•™ìŠµ',
            '28': 'ê³¼í•™ê¸°ìˆ ',
            '29': 'ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™'
        }
        
        # YouTube ì›ë³¸ ì¹´í…Œê³ ë¦¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë” ì •í™•í•œ ë¶„ë¥˜)
        # í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì†Œìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ë§Œ ë§¤í•‘
        self.app_category_mapping = {
            'ìŒì•…': 'ìŒì•…',
            'ê²Œì„': 'ê²Œì„',
            'ê³¼í•™ê¸°ìˆ ': 'ê³¼í•™ê¸°ìˆ ',
            'êµìœ¡/í•™ìŠµ': 'êµìœ¡/í•™ìŠµ',
            'ì—”í„°í…Œì¸ë¨¼íŠ¸': 'ì—”í„°í…Œì¸ë¨¼íŠ¸',
            'ë¼ì´í”„ìŠ¤íƒ€ì¼': 'ë¼ì´í”„ìŠ¤íƒ€ì¼',
            'ë‰´ìŠ¤/ì •ì¹˜': 'ë‰´ìŠ¤/ì •ì¹˜',
            'ìŠ¤í¬ì¸ ': 'ìŠ¤í¬ì¸ ',
            'ì½”ë¯¸ë””': 'ì½”ë¯¸ë””',
            'ì‚¬ëŒ/ë¸”ë¡œê·¸': 'ì‚¬ëŒ/ë¸”ë¡œê·¸',
            'ì˜í™”/ì• ë‹ˆë©”ì´ì…˜': 'ì˜í™”/ì• ë‹ˆë©”ì´ì…˜',
            'ë™ë¬¼/ë°˜ë ¤ë™ë¬¼': 'ë™ë¬¼/ë°˜ë ¤ë™ë¬¼',
            'ì—¬í–‰/ì´ë²¤íŠ¸': 'ì—¬í–‰/ì´ë²¤íŠ¸',
            'ìë™ì°¨/êµí†µ': 'ìë™ì°¨/êµí†µ',
            'ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™': 'ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™'
        }
    
    def detect_language(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ì–¸ì–´ ê°ì§€
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        
        Returns:
            ê°ì§€ëœ ì–¸ì–´ ('í•œêµ­ì–´', 'ì¼ë³¸ì–´', 'ì˜ì–´', 'ì¤‘êµ­ì–´', 'ê¸°íƒ€')
        """
        if not text:
            return 'ê¸°íƒ€'
        
        # ê° ì–¸ì–´ë³„ ë¬¸ì ê°œìˆ˜ ì¹´ìš´íŠ¸
        korean_count = 0
        japanese_count = 0
        chinese_count = 0
        english_count = 0
        
        for char in text:
            # í•œê¸€ (ê°€-í£)
            if '\uac00' <= char <= '\ud7a3':
                korean_count += 1
            # ì¼ë³¸ì–´ íˆë¼ê°€ë‚˜ (ã-ã‚“)
            elif '\u3040' <= char <= '\u309f':
                japanese_count += 1
            # ì¼ë³¸ì–´ ê°€íƒ€ì¹´ë‚˜ (ã‚¡-ãƒ¶)
            elif '\u30a0' <= char <= '\u30ff':
                japanese_count += 1
            # ì˜ì–´ (A-Z, a-z)
            elif ('A' <= char <= 'Z') or ('a' <= char <= 'z'):
                english_count += 1
            # ì¤‘êµ­ì–´ ê°„ì²´/ë²ˆì²´ (CJK Unified Ideographs)
            elif '\u4e00' <= char <= '\u9fff':
                chinese_count += 1
        
        # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì–¸ì–´ ê°ì§€
        # 1. í•œê¸€ì´ 5ê°œ ì´ìƒ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ í•œêµ­ì–´
        if korean_count >= 5:
            return 'í•œêµ­ì–´'
        
        # 2. ì¼ë³¸ì–´ ë¬¸ì(íˆë¼ê°€ë‚˜ or ê°€íƒ€ì¹´ë‚˜)ê°€ 3ê°œ ì´ìƒ ìˆìœ¼ë©´ ì¼ë³¸ì–´
        if japanese_count >= 3:
            return 'ì¼ë³¸ì–´'
        
        # 3. ì¤‘êµ­ì–´ í•œìê°€ 5ê°œ ì´ìƒ ìˆê³ , í•œê¸€/ì¼ë³¸ì–´ê°€ ì—†ìœ¼ë©´ ì¤‘êµ­ì–´
        if chinese_count >= 5 and korean_count == 0 and japanese_count == 0:
            return 'ì¤‘êµ­ì–´'
        
        # 4. ìœ„ ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ì–¸ì–´
        counts = {
            'í•œêµ­ì–´': korean_count,
            'ì¼ë³¸ì–´': japanese_count,
            'ì¤‘êµ­ì–´': chinese_count,
            'ì˜ì–´': english_count
        }
        
        max_count = max(counts.values())
        if max_count == 0:
            return 'ê¸°íƒ€'
        
        # ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ì–¸ì–´ ë°˜í™˜ (ë™ì ì¸ ê²½ìš° ìš°ì„ ìˆœìœ„)
        for lang in ['í•œêµ­ì–´', 'ì¼ë³¸ì–´', 'ì¤‘êµ­ì–´', 'ì˜ì–´']:
            if counts[lang] == max_count:
                return lang
        
        return 'ê¸°íƒ€'
    
    def get_trending_videos(
        self,
        region_code: str = 'KR',
        max_results: int = 50,
        category_id: Optional[str] = None
    ) -> List[Dict]:
        """
        ê¸‰ìƒìŠ¹ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            region_code: ì§€ì—­ ì½”ë“œ (KR=í•œêµ­, US=ë¯¸êµ­, JP=ì¼ë³¸ ë“±)
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (1-50)
            category_id: ì¹´í…Œê³ ë¦¬ ID (ì„ íƒì‚¬í•­)
        
        Returns:
            ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # API ìš”ì²­ íŒŒë¼ë¯¸í„°
            request_params = {
                'part': 'snippet,statistics,contentDetails',
                'chart': 'mostPopular',
                'regionCode': region_code,
                'maxResults': min(max_results, 50),  # API ì œí•œ: ìµœëŒ€ 50
                'videoCategoryId': category_id
            }
            
            # category_idê°€ Noneì´ë©´ ì œê±°
            if not category_id:
                del request_params['videoCategoryId']
            
            # API í˜¸ì¶œ
            request = self.youtube.videos().list(**request_params)
            response = request.execute()
            
            # ê²°ê³¼ íŒŒì‹±
            videos = []
            for item in response.get('items', []):
                video_info = self._parse_video_item(item, region_code)
                if video_info:
                    videos.append(video_info)
            
            return videos
            
        except HttpError as e:
            print(f"âŒ YouTube API ì˜¤ë¥˜: {e}")
            if e.resp.status == 403:
                print("ğŸ’¡ í• ë‹¹ëŸ‰ ì´ˆê³¼ ë˜ëŠ” API í‚¤ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                print("   - Google Cloud Consoleì—ì„œ í• ë‹¹ëŸ‰ í™•ì¸")
                print("   - API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
            return []
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return []
    
    def search_videos(
        self,
        query: str,
        max_results: int = 20,
        order: str = 'viewCount',
        published_after: Optional[datetime] = None
    ) -> List[Dict]:
        """
        í‚¤ì›Œë“œë¡œ ì˜ìƒ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ í‚¤ì›Œë“œ
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            order: ì •ë ¬ ìˆœì„œ (date, rating, relevance, title, videoCount, viewCount)
            published_after: ì´ ë‚ ì§œ ì´í›„ì— ì—…ë¡œë“œëœ ì˜ìƒë§Œ ê²€ìƒ‰
        
        Returns:
            ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ê¸°ë³¸ê°’: 3ê°œì›” ì „
            if not published_after:
                published_after = datetime.now() - timedelta(days=90)
            
            # API ìš”ì²­
            request = self.youtube.search().list(
                part='snippet',
                q=query,
                type='video',
                order=order,
                maxResults=min(max_results, 50),
                publishedAfter=published_after.isoformat() + 'Z',
                relevanceLanguage='ko'  # í•œêµ­ì–´ ì˜ìƒ ìš°ì„ 
            )
            response = request.execute()
            
            # ë¹„ë””ì˜¤ ID ì¶”ì¶œ
            video_ids = [item['id']['videoId'] for item in response.get('items', [])]
            
            # ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì¡°íšŒìˆ˜, ì¢‹ì•„ìš” ë“±)
            if video_ids:
                return self.get_videos_by_ids(video_ids)
            
            return []
            
        except HttpError as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def get_videos_by_ids(self, video_ids: List[str]) -> List[Dict]:
        """
        ë¹„ë””ì˜¤ ID ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë°°ì¹˜ ì²˜ë¦¬)
        
        Args:
            video_ids: ë¹„ë””ì˜¤ ID ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 50ê°œ)
        
        Returns:
            ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # APIëŠ” í•œ ë²ˆì— ìµœëŒ€ 50ê°œ ì²˜ë¦¬ ê°€ëŠ¥
            video_ids = video_ids[:50]
            
            request = self.youtube.videos().list(
                part='snippet,statistics,contentDetails',
                id=','.join(video_ids)
            )
            response = request.execute()
            
            videos = []
            for item in response.get('items', []):
                video_info = self._parse_video_item(item)
                if video_info:
                    videos.append(video_info)
            
            return videos
            
        except HttpError as e:
            print(f"âŒ ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def _parse_video_item(self, item: Dict, region_code: str = 'KR') -> Optional[Dict]:
        """
        YouTube API ì‘ë‹µ ì•„ì´í…œì„ ìš°ë¦¬ ì•± í˜•ì‹ìœ¼ë¡œ íŒŒì‹±
        
        Args:
            item: YouTube API ì‘ë‹µ ì•„ì´í…œ
            region_code: ì§€ì—­ ì½”ë“œ
        
        Returns:
            íŒŒì‹±ëœ ì˜ìƒ ì •ë³´
        """
        try:
            snippet = item['snippet']
            statistics = item.get('statistics', {})
            content_details = item.get('contentDetails', {})
            
            video_id = item['id']
            
            # ì¡°íšŒìˆ˜
            view_count = int(statistics.get('viewCount', 0))
            views_formatted = self._format_number(view_count)
            
            # ì¢‹ì•„ìš” ìˆ˜
            like_count = int(statistics.get('likeCount', 0))
            
            # ëŒ“ê¸€ ìˆ˜
            comment_count = int(statistics.get('commentCount', 0))
            
            # ì˜ìƒ ê¸¸ì´ (ISO 8601 durationì„ ì´ˆë¡œ ë³€í™˜)
            duration = self._parse_duration(content_details.get('duration', 'PT0S'))
            
            # ì˜ìƒ íƒ€ì… ê²°ì • (ì‡¼ì¸  vs ë¡±í¼)
            # YouTube Shorts: 60ì´ˆ ì´í•˜
            video_type = 'ì‡¼ì¸ ' if duration <= 60 else 'ë¡±í¼'
            
            # ì¹´í…Œê³ ë¦¬
            category_id = snippet.get('categoryId', '0')
            youtube_category = self.category_mapping.get(category_id, 'ê¸°íƒ€')
            app_category = self.app_category_mapping.get(youtube_category, 'ê¸°íƒ€')
            
            # ì–¸ì–´ ê°ì§€ (ì œëª© ê¸°ë°˜)
            title = snippet['title']
            language = self.detect_language(title)
            
            # ì§€ì—­
            region = 'êµ­ë‚´' if region_code == 'KR' else 'í•´ì™¸'
            
            # ì—…ë¡œë“œ ë‚ ì§œ
            published_at = snippet['publishedAt']
            
            # íŠ¸ë Œë“œ ì ìˆ˜ ê³„ì‚°
            trend_score = self._calculate_trend_score(
                view_count, like_count, comment_count, published_at
            )
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ (ì œëª©ì—ì„œ)
            keywords = self._extract_keywords(title)
            
            # ì¸ë„¤ì¼
            thumbnails = snippet.get('thumbnails', {})
            thumbnail_url = (
                thumbnails.get('high', {}).get('url') or
                thumbnails.get('medium', {}).get('url') or
                thumbnails.get('default', {}).get('url', '')
            )
            
            # ë°”ì´ëŸ´ ì´ìœ  ìƒì„±
            why_viral = self._generate_viral_reason(view_count, like_count, trend_score)
            
            # ì°¸ì—¬ë„ ê³„ì‚°
            engagement_rate = (like_count / max(view_count, 1)) * 100
            engagement = f"{engagement_rate:.1f}%"
            
            return {
                'video_id': video_id,
                'title': title,
                'views': views_formatted,
                'view_count': view_count,
                'category': app_category,
                'language': language,
                'video_type': video_type,
                'youtube_url': f"https://www.youtube.com/watch?v={video_id}",
                'thumbnail': thumbnail_url,
                'trend_score': trend_score,
                'crawled_at': datetime.now().isoformat(),
                'published_at': published_at,
                'region': region,
                'keywords': keywords,
                'why_viral': why_viral,
                'engagement': engagement,
                'like_count': like_count,
                'comment_count': comment_count,
                'duration': duration,
                'channel_title': snippet.get('channelTitle', ''),
                'description': snippet.get('description', '')[:200],
                'source': 'youtube_api'
            }
            
        except Exception as e:
            print(f"âŒ ì˜ìƒ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
    
    def _parse_duration(self, duration_str: str) -> int:
        """
        ISO 8601 durationì„ ì´ˆë¡œ ë³€í™˜
        
        ì˜ˆ: PT1H2M10S â†’ 3730ì´ˆ
            PT15M33S â†’ 933ì´ˆ
            PT45S â†’ 45ì´ˆ
        
        Args:
            duration_str: ISO 8601 í˜•ì‹ì˜ duration
        
        Returns:
            ì´ˆ ë‹¨ìœ„ ì‹œê°„
        """
        import re
        
        pattern = r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?'
        match = re.match(pattern, duration_str)
        
        if not match:
            return 0
        
        hours = int(match.group(1) or 0)
        minutes = int(match.group(2) or 0)
        seconds = int(match.group(3) or 0)
        
        return hours * 3600 + minutes * 60 + seconds
    
    def _format_number(self, num: int) -> str:
        """
        ìˆ«ìë¥¼ K, M ë‹¨ìœ„ë¡œ í¬ë§·
        
        Args:
            num: ìˆ«ì
        
        Returns:
            í¬ë§·ëœ ë¬¸ìì—´ (ì˜ˆ: 1.2M, 345K)
        """
        if num >= 1_000_000:
            return f"{num / 1_000_000:.1f}M"
        elif num >= 1_000:
            return f"{num / 1_000:.1f}K"
        else:
            return str(num)
    
    def _calculate_trend_score(
        self,
        view_count: int,
        like_count: int,
        comment_count: int,
        published_at: str
    ) -> int:
        """
        íŠ¸ë Œë“œ ì ìˆ˜ ê³„ì‚° (0-100)
        
        Args:
            view_count: ì¡°íšŒìˆ˜
            like_count: ì¢‹ì•„ìš” ìˆ˜
            comment_count: ëŒ“ê¸€ ìˆ˜
            published_at: ì—…ë¡œë“œ ë‚ ì§œ
        
        Returns:
            íŠ¸ë Œë“œ ì ìˆ˜ (0-100)
        """
        # ì¡°íšŒìˆ˜ ì ìˆ˜ (0-40)
        view_score = min(40, int(view_count / 100000))
        
        # ì¢‹ì•„ìš” ë¹„ìœ¨ ì ìˆ˜ (0-25)
        like_ratio = (like_count / max(view_count, 1)) * 100
        like_score = min(25, int(like_ratio * 5))
        
        # ëŒ“ê¸€ ì°¸ì—¬ë„ ì ìˆ˜ (0-15)
        comment_ratio = (comment_count / max(view_count, 1)) * 100
        comment_score = min(15, int(comment_ratio * 30))
        
        # ìµœì‹ ì„± ì ìˆ˜ (0-20)
        try:
            video_date = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
            days_ago = (datetime.now(video_date.tzinfo) - video_date).days
            
            if days_ago <= 1:
                recency_score = 20
            elif days_ago <= 7:
                recency_score = 15
            elif days_ago <= 30:
                recency_score = 10
            elif days_ago <= 90:
                recency_score = 5
            else:
                recency_score = 0
        except:
            recency_score = 5
        
        total_score = view_score + like_score + comment_score + recency_score
        return min(100, max(0, total_score))
    
    def _extract_keywords(self, title: str, max_keywords: int = 5) -> List[str]:
        """
        ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        
        Args:
            title: ì˜ìƒ ì œëª©
            max_keywords: ìµœëŒ€ í‚¤ì›Œë“œ ìˆ˜
        
        Returns:
            í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        # ë¶ˆìš©ì–´ ì œê±°
        stop_words = {
            'ì˜', 'ê°€', 'ì´', 'ì€', 'ë“¤', 'ëŠ”', 'ì¢€', 'ì˜', 'ê±', 'ê³¼', 'ë„', 'ë¥¼', 'ìœ¼ë¡œ', 'ì', 'ì—',
            'ì™€', 'í•œ', 'í•˜ë‹¤', 'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'
        }
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ë‹¨ì–´ ë¶„ë¦¬
        import re
        words = re.findall(r'\b\w+\b', title.lower())
        
        # ë¶ˆìš©ì–´ ì œê±° ë° ê¸¸ì´ í•„í„°
        keywords = [
            word for word in words 
            if word not in stop_words and len(word) >= 2
        ]
        
        return keywords[:max_keywords]
    
    def _generate_viral_reason(
        self,
        view_count: int,
        like_count: int,
        trend_score: int
    ) -> str:
        """
        ë°”ì´ëŸ´ ì´ìœ  ìƒì„±
        
        Args:
            view_count: ì¡°íšŒìˆ˜
            like_count: ì¢‹ì•„ìš” ìˆ˜
            trend_score: íŠ¸ë Œë“œ ì ìˆ˜
        
        Returns:
            ë°”ì´ëŸ´ ì´ìœ  ë¬¸ìì—´
        """
        reasons = [
            "ì‹¤ìš©ì ì¸ ì •ë³´ì™€ ë‹¨ê³„ë³„ ê°€ì´ë“œ",
            "ì´ˆë³´ìë„ ì‰½ê²Œ ë”°ë¼í•  ìˆ˜ ìˆëŠ” ë°©ë²•",
            "ìµœì‹  íŠ¸ë Œë“œì™€ ì‹¤ì „ ê²½í—˜ ê³µìœ ",
            "êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ê²°ê³¼ ì œì‹œ",
            "ë…íŠ¹í•œ ê´€ì ê³¼ ìƒˆë¡œìš´ ì ‘ê·¼ë²•",
            "ê°ì •ì  ëª°ì…ê³¼ ìŠ¤í† ë¦¬í…”ë§",
            "ì‹œê°ì  ì„íŒ©íŠ¸ì™€ í¸ì§‘ ê¸°ë²•",
            "ë†’ì€ ì°¸ì—¬ë„ì™€ ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘"
        ]
        
        # íŠ¸ë Œë“œ ì ìˆ˜ì— ë”°ë¼ ì´ìœ  ì„ íƒ
        if trend_score >= 80:
            return reasons[0]  # ê°€ì¥ ê°•ë ¥í•œ ì´ìœ 
        elif like_count / max(view_count, 1) > 0.05:
            return reasons[7]  # ë†’ì€ ì°¸ì—¬ë„
        else:
            return random.choice(reasons)
    
    def get_multiple_regions(
        self,
        region_codes: List[str] = ['KR', 'US', 'JP'],
        max_results_per_region: int = 20
    ) -> List[Dict]:
        """
        ì—¬ëŸ¬ ì§€ì—­ì˜ ê¸‰ìƒìŠ¹ ì˜ìƒì„ í•œ ë²ˆì— ê°€ì ¸ì˜¤ê¸°
        
        Args:
            region_codes: ì§€ì—­ ì½”ë“œ ë¦¬ìŠ¤íŠ¸
            max_results_per_region: ì§€ì—­ë‹¹ ìµœëŒ€ ê²°ê³¼ ìˆ˜
        
        Returns:
            ëª¨ë“  ì§€ì—­ì˜ ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        all_videos = []
        
        for region_code in region_codes:
            print(f"ğŸ“¡ {region_code} ì§€ì—­ ê¸‰ìƒìŠ¹ ì˜ìƒ ìˆ˜ì§‘ ì¤‘...")
            videos = self.get_trending_videos(
                region_code=region_code,
                max_results=max_results_per_region
            )
            all_videos.extend(videos)
            print(f"âœ… {region_code}: {len(videos)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ì¤‘ë³µ ì œê±° (video_id ê¸°ì¤€)
        seen_ids = set()
        unique_videos = []
        for video in all_videos:
            if video['video_id'] not in seen_ids:
                seen_ids.add(video['video_id'])
                unique_videos.append(video)
        
        # íŠ¸ë Œë“œ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        unique_videos.sort(key=lambda x: x['trend_score'], reverse=True)
        
        return unique_videos
    
    def get_trending_by_categories(
        self,
        region_code: str = 'KR',
        min_videos_per_category: int = 100
    ) -> List[Dict]:
        """
        ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê¸‰ìƒìŠ¹ ì˜ìƒì„ ìˆ˜ì§‘
        
        Args:
            region_code: ì§€ì—­ ì½”ë“œ (KR, US, JP ë“±)
            min_videos_per_category: ì¹´í…Œê³ ë¦¬ë‹¹ ìµœì†Œ ì˜ìƒ ìˆ˜
        
        Returns:
            ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        # YouTube API ì£¼ìš” ì¹´í…Œê³ ë¦¬ ID
        main_categories = {
            '10': 'ìŒì•…',
            '20': 'ê²Œì„',
            '28': 'ê³¼í•™ê¸°ìˆ ',
            '27': 'êµìœ¡/í•™ìŠµ',
            '24': 'ì—”í„°í…Œì¸ë¨¼íŠ¸',
            '26': 'ë¼ì´í”„ìŠ¤íƒ€ì¼',
            '25': 'ë‰´ìŠ¤/ì •ì¹˜',
            '17': 'ìŠ¤í¬ì¸ ',
            '23': 'ì½”ë¯¸ë””',
            '22': 'ì‚¬ëŒ/ë¸”ë¡œê·¸'
        }
        
        all_videos = []
        seen_ids = set()
        
        for category_id, category_name in main_categories.items():
            print(f"ğŸ“‚ [{category_name}] ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì¤‘...")
            
            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ 50ê°œì”© ìˆ˜ì§‘ (API ìµœëŒ€ê°’)
            videos = self.get_trending_videos(
                region_code=region_code,
                max_results=50,
                category_id=category_id
            )
            
            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ì¶”ê°€
            new_videos = 0
            for video in videos:
                if video['video_id'] not in seen_ids:
                    seen_ids.add(video['video_id'])
                    all_videos.append(video)
                    new_videos += 1
            
            print(f"âœ… [{category_name}]: {new_videos}ê°œ ì‹ ê·œ ìˆ˜ì§‘ (ì¤‘ë³µ ì œì™¸)")
        
        # íŠ¸ë Œë“œ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        all_videos.sort(key=lambda x: x['trend_score'], reverse=True)
        
        return all_videos
    
    def get_comprehensive_data(
        self,
        region_codes: List[str] = ['KR', 'US', 'JP'],
        min_videos_per_category: int = 100
    ) -> List[Dict]:
        """
        ì—¬ëŸ¬ ì§€ì—­ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¢…í•© ë°ì´í„° ìˆ˜ì§‘
        
        Args:
            region_codes: ì§€ì—­ ì½”ë“œ ë¦¬ìŠ¤íŠ¸
            min_videos_per_category: ì¹´í…Œê³ ë¦¬ë‹¹ ìµœì†Œ ì˜ìƒ ìˆ˜
        
        Returns:
            ëª¨ë“  ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        all_videos = []
        seen_ids = set()
        
        for region_code in region_codes:
            print(f"\nğŸŒ {region_code} ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
            
            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìˆ˜ì§‘
            videos = self.get_trending_by_categories(
                region_code=region_code,
                min_videos_per_category=min_videos_per_category
            )
            
            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ì¶”ê°€
            new_videos = 0
            for video in videos:
                if video['video_id'] not in seen_ids:
                    seen_ids.add(video['video_id'])
                    all_videos.append(video)
                    new_videos += 1
            
            print(f"âœ… {region_code}: ì´ {new_videos}ê°œ ì‹ ê·œ ì˜ìƒ ìˆ˜ì§‘")
        
        # íŠ¸ë Œë“œ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        all_videos.sort(key=lambda x: x['trend_score'], reverse=True)
        
        print(f"\nğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_videos)}ê°œ ì˜ìƒ")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ì¶œë ¥
        from collections import Counter
        category_counts = Counter(v['category'] for v in all_videos)
        print("\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ì˜ìƒ ìˆ˜:")
        for cat, count in category_counts.most_common():
            print(f"   {cat}: {count}ê°œ")
        
        return all_videos


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
    service = YouTubeAPIService()
    
    print("ğŸ¬ YouTube API ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸\n")
    
    # í•œêµ­ ê¸‰ìƒìŠ¹ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
    print("1ï¸âƒ£ í•œêµ­ ê¸‰ìƒìŠ¹ ì˜ìƒ TOP 10:")
    videos = service.get_trending_videos(region_code='KR', max_results=10)
    for i, video in enumerate(videos, 1):
        print(f"{i}. [{video['video_type']}] {video['title']}")
        print(f"   ì¡°íšŒìˆ˜: {video['views']} | íŠ¸ë Œë“œ: {video['trend_score']}ì ")
        print(f"   ì¹´í…Œê³ ë¦¬: {video['category']} | ì–¸ì–´: {video['language']}\n")
    
    # í‚¤ì›Œë“œ ê²€ìƒ‰
    print("\n2ï¸âƒ£ 'ë¶€ì—…' í‚¤ì›Œë“œ ê²€ìƒ‰:")
    search_results = service.search_videos('ë¶€ì—…', max_results=5)
    for i, video in enumerate(search_results, 1):
        print(f"{i}. {video['title']}")
        print(f"   ì¡°íšŒìˆ˜: {video['views']} | {video['channel_title']}\n")
    
    # ì—¬ëŸ¬ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘
    print("\n3ï¸âƒ£ í•œêµ­/ë¯¸êµ­/ì¼ë³¸ ê¸‰ìƒìŠ¹ ì˜ìƒ:")
    multi_region = service.get_multiple_regions(['KR', 'US', 'JP'], max_results_per_region=5)
    print(f"âœ… ì´ {len(multi_region)}ê°œ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ")


