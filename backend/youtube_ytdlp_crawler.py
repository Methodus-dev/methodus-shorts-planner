"""
yt-dlpë¥¼ ì‚¬ìš©í•œ YouTube ê¸‰ìƒìŠ¹ Shorts í¬ë¡¤ëŸ¬
YouTube Data API ì—†ì´ë„ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ê°€ëŠ¥
"""
import yt_dlp
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict
import re

class YouTubeYTDLPCrawler:
    def __init__(self, cache_file: str = "../data/youtube_shorts_cache.json"):
        self.cache_file = Path(cache_file)
        self.cache_file.parent.mkdir(parents=True, exist_ok=True)
    
    def get_trending_videos(self, max_results: int = 100, include_shorts: bool = True, include_long: bool = True) -> List[Dict]:
        """yt-dlpë¡œ ì‹¤ì œ ê¸‰ìƒìŠ¹ ì˜ìƒ ê°€ì ¸ì˜¤ê¸° (ì‡¼ì¸  + ë¡±í¼)"""
        
        try:
            print(f"ğŸ¬ ìµœê·¼ ê¸‰ìƒìŠ¹ YouTube ë™ì˜ìƒ ìˆ˜ì§‘ ì¤‘... (ëª©í‘œ: {max_results}ê°œ)")
            
            all_videos = []
            
            # í•œêµ­ì–´ ì˜ìƒ ìˆ˜ì§‘ (60%)
            korean_target = int(max_results * 0.6)
            korean_videos = self._search_korean_videos(korean_target)
            all_videos.extend(korean_videos)
            print(f"âœ… í•œêµ­ì–´ ê¸‰ìƒìŠ¹ ì˜ìƒ: {len(korean_videos)}ê°œ")
            
            # ì˜ì–´/ê¸€ë¡œë²Œ ì˜ìƒ ìˆ˜ì§‘ (40%)
            english_target = int(max_results * 0.4)
            global_videos = self._search_global_videos(english_target)
            all_videos.extend(global_videos)
            print(f"âœ… ì˜ì–´ ê¸‰ìƒìŠ¹ ì˜ìƒ: {len(global_videos)}ê°œ")
            
            # ì‡¼ì¸ /ë¡±í¼ í•„í„°ë§
            filtered_videos = []
            for video in all_videos:
                if include_shorts and video.get('is_shorts'):
                    filtered_videos.append(video)
                elif include_long and not video.get('is_shorts'):
                    filtered_videos.append(video)
            
            # ê¸‰ìƒìŠ¹ ìš°ì„  ì •ë ¬
            sorted_videos = self._sort_by_trend_and_recency(filtered_videos)
            print(f"ğŸ¯ ìµœì¢… ê¸‰ìƒìŠ¹ ì˜ìƒ ìˆ˜ì§‘: {len(sorted_videos)}ê°œ (íŠ¸ë Œë“œ ìš°ì„  ì •ë ¬)")
            return sorted_videos[:max_results]
            
        except Exception as e:
            print(f"âŒ yt-dlp í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            print("ğŸ”„ ì¬ì‹œë„ ì¤‘...")
            # ì¬ì‹œë„ ë¡œì§
            try:
                return self._retry_crawling(max_results, include_shorts, include_long)
            except Exception as retry_error:
                print(f"âŒ ì¬ì‹œë„ ì‹¤íŒ¨: {retry_error}")
                return []
    
    def get_trending_by_category(self, categories: List[str], per_category: int = 50) -> List[Dict]:
        """ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì˜ìƒ ìˆ˜ì§‘ (í•œêµ­ì–´ 60% + ì˜ì–´ 40%)"""
        all_videos = []
        
        for category in categories:
            print(f"ğŸ“‚ {category} ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì¤‘ (ëª©í‘œ: {per_category}ê°œ)...")
            try:
                # í•œêµ­ì–´ 60%, ì˜ì–´ 40%
                korean_count = int(per_category * 0.6)
                english_count = int(per_category * 0.4)
                
                # í•œêµ­ì–´ ì˜ìƒ
                category_videos_kr = self._search_by_category(category, korean_count)
                all_videos.extend(category_videos_kr)
                
                # ì˜ì–´ ì˜ìƒ (ì¹´í…Œê³ ë¦¬ì˜ ì˜ì–´ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰)
                category_videos_en = self._search_by_category_english(category, english_count)
                all_videos.extend(category_videos_en)
                
                total_collected = len(category_videos_kr) + len(category_videos_en)
                print(f"   âœ… {total_collected}ê°œ ìˆ˜ì§‘ ì™„ë£Œ (í•œêµ­ì–´: {len(category_videos_kr)}, ì˜ì–´: {len(category_videos_en)})")
            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {e}")
        
        print(f"\nğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_videos)}ê°œ ì˜ìƒ")
        return all_videos
    
    def _search_by_category_english(self, category: str, max_results: int) -> List[Dict]:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ì˜ì–´ ì˜ìƒ ê²€ìƒ‰"""
        # ì¹´í…Œê³ ë¦¬ë³„ ì˜ì–´ ê²€ìƒ‰ í‚¤ì›Œë“œ
        category_keywords_en = {
            'ì°½ì—…/ë¶€ì—…': ['side hustle', 'startup', 'business', 'entrepreneur', 'make money'],
            'ì¬í…Œí¬/ê¸ˆìœµ': ['investing', 'stock market', 'real estate', 'crypto', 'money'],
            'ê³¼í•™ê¸°ìˆ ': ['AI', 'ChatGPT', 'coding', 'programming', 'tech', 'app'],
            'ìê¸°ê³„ë°œ': ['self improvement', 'productivity', 'motivation', 'success', 'habits'],
            'ë§ˆì¼€íŒ…/ë¹„ì¦ˆë‹ˆìŠ¤': ['marketing', 'social media', 'instagram', 'youtube', 'branding'],
            'ìš”ë¦¬/ìŒì‹': ['cooking', 'recipe', 'food', 'baking', 'meal prep'],
            'ê²Œì„': ['gaming', 'gameplay', 'esports', 'minecraft', 'fortnite'],
            'ìš´ë™/ê±´ê°•': ['workout', 'fitness', 'diet', 'gym', 'exercise'],
            'êµìœ¡/í•™ìŠµ': ['education', 'learning', 'study', 'tutorial', 'course'],
            'ìŒì•…': ['music', 'song', 'cover', 'remix', 'beats']
        }
        
        keywords = category_keywords_en.get(category, ['trending'])
        videos = []
        
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': True,
        }
        
        per_keyword = max(5, max_results // len(keywords))
        
        for keyword in keywords:
            if len(videos) >= max_results:
                break
            
            try:
                search_url = f'ytsearch{per_keyword}:{keyword}'
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    result = ydl.extract_info(search_url, download=False)
                    
                    if result and 'entries' in result:
                        for entry in result['entries']:
                            if entry and len(videos) < max_results:
                                video_info = self._parse_ytdlp_data(entry, is_korean=False)
                                if video_info:
                                    video_info['category'] = category  # ì¹´í…Œê³ ë¦¬ ê°•ì œ ì„¤ì •
                                    videos.append(video_info)
            except Exception as e:
                continue
        
        return videos
    
    def _search_by_category(self, category: str, max_results: int) -> List[Dict]:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ì¸ê¸° ì˜ìƒ ê²€ìƒ‰"""
        # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ
        category_keywords = {
            'ì°½ì—…/ë¶€ì—…': ['ë¶€ì—…', 'ì°½ì—…', 'ì‚¬ì—…', 'ìŠ¤íƒ€íŠ¸ì—…', 'nì¡', 'íˆ¬ì¡'],
            'ì¬í…Œí¬/ê¸ˆìœµ': ['ì¬í…Œí¬', 'ì£¼ì‹', 'íˆ¬ì', 'ë¶€ë™ì‚°', 'ì½”ì¸', 'ëˆë²„ëŠ”ë²•'],
            'ê³¼í•™ê¸°ìˆ ': ['ChatGPT', 'AI', 'ì½”ë”©', 'í”„ë¡œê·¸ë˜ë°', 'ê°œë°œ', 'ì•±ê°œë°œ'],
            'ìê¸°ê³„ë°œ': ['ìê¸°ê³„ë°œ', 'ë£¨í‹´', 'ìŠµê´€', 'ë™ê¸°ë¶€ì—¬', 'ì„±ê³µ', 'ëª©í‘œ'],
            'ë§ˆì¼€íŒ…/ë¹„ì¦ˆë‹ˆìŠ¤': ['ë§ˆì¼€íŒ…', 'SNS', 'ì¸ìŠ¤íƒ€', 'ìœ íŠœë¸Œ', 'ë¸Œëœë”©', 'ê´‘ê³ '],
            'ìš”ë¦¬/ìŒì‹': ['ìš”ë¦¬', 'ë ˆì‹œí”¼', 'ê°„ë‹¨ìš”ë¦¬', 'ë¨¹ë°©', 'ë§›ì§‘', 'ë‹¤ì´ì–´íŠ¸ì‹ë‹¨'],
            'ê²Œì„': ['ê²Œì„', 'ë¡¤', 'ë°°ê·¸', 'LOL', 'FIFA', 'ë§ˆì¸í¬ë˜í”„íŠ¸'],
            'ìš´ë™/ê±´ê°•': ['ìš´ë™', 'í—¬ìŠ¤', 'ë‹¤ì´ì–´íŠ¸', 'í™ˆíŠ¸', 'ìš”ê°€', 'í•„ë¼í…ŒìŠ¤'],
            'êµìœ¡/í•™ìŠµ': ['ê³µë¶€', 'ì˜ì–´', 'í•™ìŠµ', 'ìˆ˜í—˜ìƒ', 'ê³µë¬´ì›', 'ìê²©ì¦'],
            'ìŒì•…': ['ë…¸ë˜', 'ìŒì•…', 'K-POP', 'ê°€ìˆ˜', 'ë®¤ì§ë¹„ë””ì˜¤', 'ì»¤ë²„']
        }
        
        keywords = category_keywords.get(category, [category])
        videos = []
        
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': True,
        }
        
        per_keyword = max(10, max_results // len(keywords))
        
        for keyword in keywords:
            if len(videos) >= max_results:
                break
            
            try:
                search_url = f'ytsearch{per_keyword}:{keyword}'
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    result = ydl.extract_info(search_url, download=False)
                    
                    if result and 'entries' in result:
                        for entry in result['entries']:
                            if entry and len(videos) < max_results:
                                video_info = self._parse_ytdlp_data(entry, is_korean=True)
                                if video_info:
                                    video_info['category'] = category  # ì¹´í…Œê³ ë¦¬ ê°•ì œ ì„¤ì •
                                    videos.append(video_info)
            except Exception as e:
                continue
        
        return videos
    
    def _search_korean_videos(self, max_results: int) -> List[Dict]:
        """í•œêµ­ì–´ ì¸ê¸° ì˜ìƒ ê²€ìƒ‰"""
        videos = []
        
        # í•œêµ­ì–´ ì¸ê¸° í‚¤ì›Œë“œë“¤
        korean_keywords = [
            'ë¶€ì—…', 'ì¬í…Œí¬', 'ì£¼ì‹', 'ChatGPT', 'ë§ˆì¼€íŒ…', 
            'ìê¸°ê³„ë°œ', 'ìš”ë¦¬', 'ê²Œì„', 'ìš´ë™', 'ê³µë¶€'
        ]
        
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': True,
        }
        
        per_keyword = max(5, max_results // len(korean_keywords))
        
        for keyword in korean_keywords:
            if len(videos) >= max_results:
                break
            
            try:
                search_url = f'ytsearch{per_keyword}:{keyword}'
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    result = ydl.extract_info(search_url, download=False)
                    
                    if result and 'entries' in result:
                        for entry in result['entries']:
                            if entry and len(videos) < max_results:
                                video_info = self._parse_ytdlp_data(entry, is_korean=True)
                                if video_info:
                                    videos.append(video_info)
            except Exception as e:
                continue
        
        return videos
    
    def _search_global_videos(self, max_results: int) -> List[Dict]:
        """ê¸€ë¡œë²Œ ì¸ê¸° ì˜ìƒ ê²€ìƒ‰ (ì˜ì–´)"""
        videos = []
        
        # ì˜ì–´ ì¸ê¸° í‚¤ì›Œë“œë“¤
        english_keywords = [
            'side hustle', 'make money online', 'AI tools', 'productivity', 
            'entrepreneur', 'business', 'investing', 'crypto', 'fitness', 'cooking'
        ]
        
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': True,
        }
        
        per_keyword = max(5, max_results // len(english_keywords))
        
        for keyword in english_keywords:
            if len(videos) >= max_results:
                break
            
            try:
                search_url = f'ytsearch{per_keyword}:{keyword}'
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    result = ydl.extract_info(search_url, download=False)
                    
                    if result and 'entries' in result:
                        for entry in result['entries']:
                            if entry and len(videos) < max_results:
                                video_info = self._parse_ytdlp_data(entry, is_korean=False)
                                if video_info:
                                    videos.append(video_info)
            except Exception as e:
                continue
        
        return videos
    
    def _parse_ytdlp_data(self, entry: dict, is_korean: bool = False) -> Dict:
        """yt-dlp ë°ì´í„° íŒŒì‹±"""
        try:
            title = entry.get('title', '')
            video_id = entry.get('id', '')
            view_count = entry.get('view_count', 0)
            duration = entry.get('duration', 0)
            
            if not title or not video_id:
                return None
            
            # ì‡¼ì¸  ì—¬ë¶€ íŒë‹¨ (60ì´ˆ ì´í•˜)
            is_shorts = duration and duration <= 60
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(title)
            category = self._estimate_category(title, keywords)
            
            # ì§€ì—­/ì–¸ì–´ íŒë‹¨ - ì œëª©ì˜ ì‹¤ì œ ì–¸ì–´ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
            has_korean = bool(re.search(r'[ê°€-í£]', title))
            korean_ratio = len(re.findall(r'[ê°€-í£]', title)) / len(title) if len(title) > 0 else 0
            
            # í•œê¸€ì´ 30% ì´ìƒì´ë©´ í•œêµ­ì–´, ì•„ë‹ˆë©´ ì˜ì–´
            if korean_ratio >= 0.1 or has_korean:
                region = "êµ­ë‚´"
                language = "í•œêµ­ì–´"
            else:
                region = "í•´ì™¸"
                language = "ì˜ì–´"
            
            return {
                "title": title,
                "category": category,
                "views": self._format_views(view_count),
                "engagement": self._calculate_engagement(view_count),
                "keywords": keywords,
                "thumbnail": self._get_emoji(category),
                "why_viral": self._analyze_viral(title, view_count),
                "video_id": video_id,
                "youtube_url": f"https://www.youtube.com/watch?v={video_id}",
                "shorts_url": f"https://www.youtube.com/shorts/{video_id}",
                "is_shorts": is_shorts,
                "video_type": "ì‡¼ì¸ " if is_shorts else "ë¡±í¼",
                "duration": duration,
                "region": region,
                "language": language,
                "trend_score": self._calculate_trend_score(view_count),
                "crawled_at": datetime.now().isoformat()
            }
        except Exception as e:
            return None
    
    def _format_views(self, count: int) -> str:
        """ì¡°íšŒìˆ˜ í¬ë§·"""
        if count >= 1000000:
            return f"{count/1000000:.1f}M"
        elif count >= 1000:
            return f"{count/1000:.0f}K"
        return str(count)
    
    def _calculate_engagement(self, view_count: int) -> str:
        """ì°¸ì—¬ë„ ê³„ì‚°"""
        if view_count >= 1000000:
            return "ë§¤ìš°ë†’ìŒ"
        elif view_count >= 100000:
            return "ë†’ìŒ"
        return "ë³´í†µ"
    
    def _calculate_trend_score(self, view_count: int) -> int:
        """íŠ¸ë Œë“œ ì ìˆ˜"""
        if view_count >= 5000000:
            return 100
        elif view_count >= 1000000:
            return 95
        elif view_count >= 500000:
            return 90
        elif view_count >= 100000:
            return 85
        return 70
    
    def _extract_keywords(self, title: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ - ë” ë§ì€ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keyword_patterns = {
            'ë¶€ì—…': r'ë¶€ì—…|ì‚¬ì´ë“œ|nì¡|íˆ¬ì¡|side.*hustle',
            'ì¬í…Œí¬': r'ì¬í…Œí¬|ëˆ|ìˆ˜ìµ|ë²Œê¸°|money|earn',
            'íˆ¬ì': r'íˆ¬ì|ì£¼ì‹|ë¶€ë™ì‚°|ì½”ì¸|stock|invest',
            'AI': r'AI|ChatGPT|ì¸ê³µì§€ëŠ¥|artificial',
            'ê°œë°œ': r'ê°œë°œ|ì½”ë”©|í”„ë¡œê·¸ë˜ë°|coding|programming|dev',
            'ë§ˆì¼€íŒ…': r'ë§ˆì¼€íŒ…|SNS|ì¸ìŠ¤íƒ€|í‹±í†¡|marketing|instagram|tiktok',
            'ì°½ì—…': r'ì°½ì—…|ì‚¬ì—…|ìŠ¤íƒ€íŠ¸ì—…|business|startup|entrepreneur',
            'ìê¸°ê³„ë°œ': r'ìê¸°ê³„ë°œ|ë£¨í‹´|ìŠµê´€|ë™ê¸°ë¶€ì—¬|motivation|routine|habit',
            'ìš”ë¦¬': r'ìš”ë¦¬|ë ˆì‹œí”¼|ë¨¹ë°©|ìŒì‹|cook|recipe|food',
            'ê²Œì„': r'ê²Œì„|ë¡¤|ë°°ê·¸|game|gaming|lol',
            'ìš´ë™': r'ìš´ë™|í—¬ìŠ¤|ë‹¤ì´ì–´íŠ¸|workout|fitness|diet',
            'ê³µë¶€': r'ê³µë¶€|í•™ìŠµ|ì˜ì–´|study|learn|english',
            'ë¸Œì´ë¡œê·¸': r'ë¸Œì´ë¡œê·¸|ì¼ìƒ|ë£¨í‹´|vlog|daily',
            'ë¦¬ë·°': r'ë¦¬ë·°|ì¶”ì²œ|ë¹„êµ|review|recommend',
            'ê¿€íŒ': r'ê¿€íŒ|ë¹„ë²•|ë°©ë²•|ë…¸í•˜ìš°|tip|trick|hack'
        }
        
        keywords = []
        for keyword, pattern in keyword_patterns.items():
            if re.search(pattern, title, re.IGNORECASE):
                keywords.append(keyword)
        
        # í•´ì‹œíƒœê·¸ì—ì„œ ì¶”ê°€ í‚¤ì›Œë“œ ì¶”ì¶œ
        hashtags = re.findall(r'#(\w+)', title)
        for tag in hashtags[:3]:
            if len(tag) > 2 and tag not in keywords:
                keywords.append(tag)
        
        return keywords[:10] if keywords else ['íŠ¸ë Œë“œ']
    
    def _estimate_category(self, title: str, keywords: List[str]) -> str:
        """ì¹´í…Œê³ ë¦¬ ì¶”ì •"""
        if any(k in keywords for k in ['ë¶€ì—…', 'ì°½ì—…']):
            return 'ì°½ì—…/ë¶€ì—…'
        elif any(k in keywords for k in ['ì¬í…Œí¬', 'íˆ¬ì']):
            return 'ì¬í…Œí¬/ê¸ˆìœµ'
        elif 'AI' in keywords or 'ê°œë°œ' in keywords:
            return 'ê³¼í•™ê¸°ìˆ '
        elif 'ë§ˆì¼€íŒ…' in keywords:
            return 'ë§ˆì¼€íŒ…/ë¹„ì¦ˆë‹ˆìŠ¤'
        elif 'ìê¸°ê³„ë°œ' in keywords:
            return 'ìê¸°ê³„ë°œ'
        return 'ì¼ë°˜'
    
    def _get_emoji(self, category: str) -> str:
        """ì¹´í…Œê³ ë¦¬ë³„ ì´ëª¨ì§€"""
        emojis = {
            'ì°½ì—…/ë¶€ì—…': 'ğŸ’¼', 'ì¬í…Œí¬/ê¸ˆìœµ': 'ğŸ’°', 'ê³¼í•™ê¸°ìˆ ': 'ğŸ”¬',
            'ìê¸°ê³„ë°œ': 'ğŸ’ª', 'ë§ˆì¼€íŒ…/ë¹„ì¦ˆë‹ˆìŠ¤': 'ğŸ“±', 'ê²Œì„': 'ğŸ®',
            'ìš”ë¦¬/ìŒì‹': 'ğŸ³', 'êµìœ¡': 'ğŸ“š', 'ìŒì•…': 'ğŸµ'
        }
        return emojis.get(category, 'ğŸ¬')
    
    def _analyze_viral(self, title: str, view_count: int) -> str:
        """ë°”ì´ëŸ´ ìš”ì†Œ ë¶„ì„"""
        elements = []
        
        if view_count >= 1000000:
            elements.append("ì´ˆê³ ì¡°íšŒìˆ˜")
        
        if re.search(r'\d+ë§Œì›|\d+ì–µ', title):
            elements.append("êµ¬ì²´ì  ê¸ˆì•¡")
        if re.search(r'\d+ê°œì›”|\d+ì¼', title):
            elements.append("ê¸°ê°„ ëª…ì‹œ")
        if re.search(r'ë¹„ë²•|ê¿€íŒ|ë°©ë²•', title):
            elements.append("í•˜ìš°íˆ¬")
        
        return " + ".join(elements) if elements else "ì¸ê¸° ê¸‰ìƒìŠ¹"
    
    def _retry_crawling(self, max_results: int, include_shorts: bool, include_long: bool) -> List[Dict]:
        """í¬ë¡¤ë§ ì¬ì‹œë„ - ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©"""
        print("ğŸ”„ ì‹¤ì œ í¬ë¡¤ë§ ì¬ì‹œë„ ì¤‘...")
        
        try:
            videos = []
            search_terms = ['trending', 'viral', 'popular', 'shorts']
            
            for term in search_terms:
                if len(videos) >= max_results:
                    break
                    
                try:
                    search_url = f'ytsearch{max_results//len(search_terms)}:{term}'
                    ydl_opts = {
                        'quiet': True,
                        'no_warnings': True,
                        'extract_flat': True,
                    }
                    
                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        result = ydl.extract_info(search_url, download=False)
                        
                        if result and 'entries' in result:
                            for entry in result['entries']:
                                if entry and len(videos) < max_results:
                                    video_info = self._parse_ytdlp_data(entry)
                                    if video_info:
                                        videos.append(video_info)
                except Exception as e:
                    continue
            
            print(f"âœ… ì¬ì‹œë„ ì„±ê³µ: {len(videos)}ê°œ ì‹¤ì œ ì˜ìƒ ìˆ˜ì§‘")
            return videos
            
        except Exception as e:
            print(f"âŒ ì¬ì‹œë„ ì‹¤íŒ¨: {e}")
            return []
    
    def save_to_cache(self, data: List[Dict]):
        """ìºì‹œ ì €ì¥"""
        cache_data = {
            "last_updated": datetime.now().isoformat(),
            "videos": data,
            "count": len(data),
            "source": "yt-dlp_crawler"
        }
        
        with open(self.cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ìºì‹œ ì €ì¥ ì™„ë£Œ: {len(data)}ê°œ ì˜ìƒ")
    
    def _sort_by_trend_and_recency(self, videos: List[Dict]) -> List[Dict]:
        """íŠ¸ë Œë“œ ì ìˆ˜ì™€ ìµœì‹ ì„±ì„ ì¢…í•©í•˜ì—¬ ì •ë ¬ (ê¸‰ìƒìŠ¹ ìš°ì„ )"""
        def sort_key(video):
            trend_score = video.get('trend_score', 0)
            views = video.get('views', 0)
            # íŠ¸ë Œë“œ ì ìˆ˜ 70%, ì¡°íšŒìˆ˜ 30% ê°€ì¤‘ì¹˜
            return (trend_score * 0.7) + (views / 1000000 * 0.3)
        
        return sorted(videos, key=sort_key, reverse=True)

if __name__ == "__main__":
    crawler = YouTubeYTDLPCrawler()
    print("ğŸ¬ 100ê°œ ì˜ìƒ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (ì‡¼ì¸ +ë¡±í¼, í•œêµ­ì–´+ì˜ì–´)...")
    videos = crawler.get_trending_videos(100, True, True)
    
    if videos:
        print(f"\nğŸ“Š ìˆ˜ì§‘ëœ ì˜ìƒ {len(videos)}ê°œ:")
        shorts = [v for v in videos if v.get('is_shorts')]
        longs = [v for v in videos if not v.get('is_shorts')]
        korean = [v for v in videos if v.get('language') == 'í•œêµ­ì–´']
        
        print(f"   ì‡¼ì¸ : {len(shorts)}ê°œ | ë¡±í¼: {len(longs)}ê°œ")
        print(f"   í•œêµ­ì–´: {len(korean)}ê°œ | ì˜ì–´: {len(videos) - len(korean)}ê°œ")
        print(f"\nìƒìœ„ 5ê°œ:")
        for i, v in enumerate(videos[:5], 1):
            print(f"{i}. {v['title'][:60]}...")
            print(f"   {v['video_type']} | {v['views']} | {v['language']}")
            print(f"   {v['youtube_url']}")
    else:
        print("\nâš ï¸ ì˜ìƒ ìˆ˜ì§‘ ì‹¤íŒ¨")

